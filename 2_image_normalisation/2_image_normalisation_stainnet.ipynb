{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StainNET\n",
    "All the codes in this notebook are referred to the **StainNET package** and the relative [paper](https://www.frontiersin.org/journals/medicine/articles/10.3389/fmed.2021.746307/full).\\\n",
    "StainNET is derived from the StainGAN algorithm, in fact, both the algorithms will be applied.\n",
    "\n",
    "StainNET repository and relative tutorial notebook:\\\n",
    "https://github.com/khtao/StainNet\\\n",
    "https://github.com/khtao/StainNet/blob/master/demo.ipynb\n",
    "\n",
    "StainGAN:\\\n",
    "https://github.com/xtarx/StainGAN\n",
    "\n",
    "\n",
    "Once again, the author suggests to use the conda through this [link](https://anaconda.org/conda-forge/python-spams) and the related code for installing the SPAMS dependency:\n",
    "```bash\n",
    "conda install conda-forge::python-spams\n",
    "conda install conda-forge/label/broken::python-spams\n",
    "conda install conda-forge/label/cf201901::python-spams\n",
    "conda install conda-forge/label/cf202003::python-spams\n",
    "conda install conda-forge/label/gcc7::python-spams\n",
    "```\n",
    "\n",
    "moreover, the package GitHub repository had to be cloned in the `../data/packages/` folder for successfully being able to import the pre-trained models:\n",
    "```bash\n",
    "git clone https://github.com/khtao/StainNet.git\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 0. - Imports and setting paths\n",
    "\n",
    "In this case we have to set the working directory at first because we have to import the NN models from the previously downloaded `models.py`file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import subprocess\n",
    "import torch\n",
    "import sys\n",
    "import datetime\n",
    "from PIL import Image \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/disk2/work/gabgam/gigi_env/the_project/2_image_normalisation\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/disk2/user/gabgam/work/gigi_env/the_project/2_image_normalisation/\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../data/packages/StainNet/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import StainNet, ResnetGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting a single GPU as the only visible one\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # 0 = first GPU, 1 = second GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #INPUT_FOLDER = \"../1_tiling/output/satac_C1/tiling_output/v3_allspots/tiles_100/\"  # Replace with the path to your folder containing images\n",
    "# INPUT_FOLDER = \"../1_tiling/output/satac_C1/tiling_output/v3_allspots/tiles_68/\"  # Replace with the path to your folder containing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUT_FOLDER = \"../1_tiling/output/visium_2022_FF_WG_10X/tiling_output/img_not_changed_allspots/tiles_100\"  # Replace with the path to your folder containing images\n",
    "# INPUT_FOLDER = \"../1_tiling/output/visium_2022_FF_WG_10X/tiling_output/img_not_changed_allspots/tiles_68\"  # Replace with the path to your folder containing images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT_FOLDER = \"../1_tiling/output/visium_FFPE_dcis_idc_10X/tiling_output/img_not_changed_allspots/tiles_100\"  # Replace with the path to your folder containing images\n",
    "INPUT_FOLDER = \"../1_tiling/output/visium_FFPE_dcis_idc_10X/tiling_output/img_not_changed_allspots/tiles_68\"  # Replace with the path to your folder containing images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. - Normalisation\n",
    "\n",
    "In this case, normalisation doesn't work with a target image.\\\n",
    "The idea is that the NN has to be trained and then normalisation will be perfored on our images, so, we can say that the \"target\" are the images used for the training of the network. In my case, I'll not train the model as right now I don't have time to do that, maybe in the future I'll do it, but now I'll simply use the pretrained models proposed by the [package](https://github.com/khtao/StainNet/tree/master/checkpoints).\\\n",
    "I would like to highlight that one of these models was trained with the very large [Camelyon16 imaging dataset](https://camelyon16.grand-challenge.org/), derived from sentinel lymph nodes of breast cancer patients of two different medical centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['StainNet-Public-centerUni_layer3_ch32.pth', 'latest_net_G_A.pth', 'latest_net_G_B.pth']\n"
     ]
    }
   ],
   "source": [
    "pretrained_models_path = '../data/packages/StainNet/checkpoints/camelyon16_dataset/'\n",
    "print(os.listdir(pretrained_models_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to define some functions that are useful for our purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(image):\n",
    "    image = np.array(image).astype(np.float32)\n",
    "    image = image.transpose((2, 0, 1))\n",
    "    image = ((image / 255) - 0.5) / 0.5\n",
    "    image=image[np.newaxis, ...]\n",
    "    image=torch.from_numpy(image)\n",
    "    return image\n",
    "\n",
    "def un_norm(image):\n",
    "    image = image.cpu().detach().numpy()[0]\n",
    "    image = ((image * 0.5 + 0.5) * 255).astype(np.uint8).transpose((1,2,0))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 - StainGAN normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./output/visium_FFPE_dcis_idc_10X/img_not_changed_allspots/tiles_68/stainGAN\n"
     ]
    }
   ],
   "source": [
    "# setting the paths\n",
    "normalisation_method = 'stainGAN'\n",
    "\n",
    "tiles_info = INPUT_FOLDER.split('/')\n",
    "\n",
    "# Remember: no target needed\n",
    "output_folder = f\"./output/{tiles_info[3]}/{tiles_info[5]}/{tiles_info[6]}/{normalisation_method}\"\n",
    "print(output_folder)\n",
    "\n",
    "# Let's create the output folder files\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the pre-trained NN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 - Model A: pre-trained for StainGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the first model: `latest_net_G_A.pth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2933839/2981701424.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_GAN.load_state_dict(torch.load('../data/packages/StainNet/checkpoints/camelyon16_dataset/latest_net_G_A.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load pretrained StainGAN\n",
    "model_GAN = ResnetGenerator(3, 3, ngf=64, norm_layer=torch.nn.InstanceNorm2d, n_blocks=9).cuda()\n",
    "model_GAN.load_state_dict(torch.load('../data/packages/StainNet/checkpoints/camelyon16_dataset/latest_net_G_A.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real looping normalisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished! The normalisation took 0:00:28.313588 seconds!\n"
     ]
    }
   ],
   "source": [
    "starttime = datetime.datetime.now()\n",
    "\n",
    "# Path for model A\n",
    "output_folder_model_A = os.path.join(output_folder, \"model_A\")\n",
    "os.makedirs(output_folder_model_A, exist_ok=True)\n",
    "\n",
    "# ---------------------------------------------------------------------------------\n",
    "# File to log images that fail normalization\n",
    "normalisation_fails_file = f\"{output_folder_model_A}/0_failed_to_normalise.txt\" # 0 just for having the file listed as first\n",
    "\n",
    "with open(normalisation_fails_file, \"w\") as file:\n",
    "    file.write(\"The following are the tiles not normalised:\\n\")\n",
    "    \n",
    "    # Process each image in the input folder\n",
    "    for filename in os.listdir(INPUT_FOLDER):\n",
    "        image_path = os.path.join(INPUT_FOLDER, filename)\n",
    "\n",
    "        # Load and preprocess the image\n",
    "        img = Image.open(image_path).convert(\"RGB\")\n",
    "        # print(img.size)\n",
    "        try:\n",
    "            # Perform normalization\n",
    "            model_GAN.eval()\n",
    "            with torch.no_grad():\n",
    "                img_gan=model_GAN(norm(img).cuda())\n",
    "                img_normed_array = un_norm(img_gan)\n",
    "                # print(f\"Normalized array shape: {img_normed_array.shape}\")\n",
    "                \n",
    "            # Convert the normalized image back to PIL format\n",
    "            img_normed_pil = Image.fromarray(img_normed_array)\n",
    "            \n",
    "            # Ensure output matches input size\n",
    "            if img_normed_pil.size != img.size:\n",
    "                print(f\"Had to perform resizing step! Original size = {img.size}, Size after GAN normalization = {img_normed_pil.size}\")\n",
    "                img_normed_pil = img_normed_pil.resize(img.size, Image.Resampling.LANCZOS)\n",
    "                    \n",
    "            #print(img_normed_pil.size)\n",
    "            # Save the normalized image\n",
    "            output_path = os.path.join(output_folder_model_A, f\"{os.path.splitext(filename)[0]}_{normalisation_method}_modelA.jpg\") # or .png (but it's way bigger)\n",
    "            img_normed_pil.save(output_path)\n",
    "\n",
    "            #print(f\"Normalized image saved to: {output_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            file.write(f\"{filename}\\n\")\n",
    "            #print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "\n",
    "difference =  datetime.datetime.now() - starttime\n",
    "\n",
    "# eventually deleting the previous time log file\n",
    "for filename in os.listdir(output_folder_model_A):\n",
    "    if filename.startswith(\"0_started_\"):\n",
    "        file_path = os.path.join(output_folder_model_A, filename)\n",
    "        if os.path.isfile(file_path):  # Check if it is a file\n",
    "            os.remove(file_path)      # Delete the file\n",
    "            print(f\"Deleted: {file_path}\")\n",
    "\n",
    "# saving the start and finish time in the file's name for simplicity in the reading.\n",
    "with open(f\"{output_folder_model_A}/0_started_at_{starttime}_finished_at_{datetime.datetime.now()}.txt\", \"w\") as file:\n",
    "    file.write(f\"The run started at {starttime} and finished at {datetime.datetime.now()}.\")\n",
    "\n",
    "print(f\"Finished! The normalisation took {difference} seconds!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 - Model B: pre-trained for StainGAN\n",
    "Let's load the second model: `latest_net_G_B.pth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2933839/4139838485.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_GAN.load_state_dict(torch.load('../data/packages/StainNet/checkpoints/camelyon16_dataset/latest_net_G_B.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load pretrained StainGAN\n",
    "model_GAN = ResnetGenerator(3, 3, ngf=64, norm_layer=torch.nn.InstanceNorm2d, n_blocks=9).cuda()\n",
    "model_GAN.load_state_dict(torch.load('../data/packages/StainNet/checkpoints/camelyon16_dataset/latest_net_G_B.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real looping normalisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished! The normalisation took 0:00:19.080976 seconds!\n"
     ]
    }
   ],
   "source": [
    "starttime = datetime.datetime.now()\n",
    "\n",
    "# Path for model A\n",
    "output_folder_model_B = os.path.join(output_folder, \"model_B\")\n",
    "os.makedirs(output_folder_model_B, exist_ok=True)\n",
    "\n",
    "# ---------------------------------------------------------------------------------\n",
    "# File to log images that fail normalization\n",
    "normalisation_fails_file = f\"{output_folder_model_B}/0_failed_to_normalise.txt\" # 0 just for having the file listed as first\n",
    "\n",
    "with open(normalisation_fails_file, \"w\") as file:\n",
    "    file.write(\"The following are the tiles not normalised:\\n\")\n",
    "    \n",
    "    # Process each image in the input folder\n",
    "    for filename in os.listdir(INPUT_FOLDER):\n",
    "        image_path = os.path.join(INPUT_FOLDER, filename)\n",
    "\n",
    "        # Load and preprocess the image\n",
    "        img = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        try:\n",
    "            # Perform normalization\n",
    "            model_GAN.eval()\n",
    "            with torch.no_grad():\n",
    "                img_gan=model_GAN(norm(img).cuda())\n",
    "                img_normed_array=un_norm(img_gan)\n",
    "\n",
    "            # Convert the normalized image back to PIL format\n",
    "            img_normed_pil = Image.fromarray(img_normed_array)\n",
    "            \n",
    "            # Ensure output matches input size\n",
    "            if img_normed_pil.size != img.size:\n",
    "                print(f\"Had to perform resizing step! Original size = {img.size}, Size after GAN normalization = {img_normed_pil.size}\")\n",
    "                img_normed_pil = img_normed_pil.resize(img.size, Image.Resampling.LANCZOS)\n",
    "            \n",
    "            # Save the normalized image\n",
    "            output_path = os.path.join(output_folder_model_B, f\"{os.path.splitext(filename)[0]}_{normalisation_method}_modelB.jpg\") # or .png (but it's way bigger)\n",
    "            img_normed_pil.save(output_path)\n",
    "\n",
    "            #print(f\"Normalized image saved to: {output_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            file.write(f\"{filename}\\n\")\n",
    "            #print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "\n",
    "difference =  datetime.datetime.now() - starttime\n",
    "\n",
    "# eventually deleting the previous time log file\n",
    "for filename in os.listdir(output_folder_model_B):\n",
    "    if filename.startswith(\"0_started_\"):\n",
    "        file_path = os.path.join(output_folder_model_B, filename)\n",
    "        if os.path.isfile(file_path):  # Check if it is a file\n",
    "            os.remove(file_path)      # Delete the file\n",
    "            print(f\"Deleted: {file_path}\")\n",
    "\n",
    "# saving the start and finish time in the file's name for simplicity in the reading.\n",
    "with open(f\"{output_folder_model_B}/0_started_at_{starttime}_finished_at_{datetime.datetime.now()}.txt\", \"w\") as file:\n",
    "    file.write(f\"The run started at {starttime} and finished at {datetime.datetime.now()}.\")\n",
    "\n",
    "print(f\"Finished! The normalisation took {difference} seconds!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 - StainNET normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set the correct paths and load the real StainNET pre-trained model `StainNet-Public-centerUni_layer3_ch32.pth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./output/visium_FFPE_dcis_idc_10X/img_not_changed_allspots/tiles_68/stainNET\n"
     ]
    }
   ],
   "source": [
    "# setting the paths\n",
    "normalisation_method = 'stainNET'\n",
    "\n",
    "tiles_info = INPUT_FOLDER.split('/')\n",
    "\n",
    "# Remember: no target needed\n",
    "output_folder_stainnet = f\"./output/{tiles_info[3]}/{tiles_info[5]}/{tiles_info[6]}/{normalisation_method}\"\n",
    "print(output_folder_stainnet)\n",
    "\n",
    "# Let's create the output folder files\n",
    "os.makedirs(output_folder_stainnet, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load  pretrained StainNet\n",
    "model_Net = StainNet().cuda()\n",
    "model_Net.load_state_dict(torch.load(\"../data/packages/StainNet/checkpoints/camelyon16_dataset/StainNet-Public-centerUni_layer3_ch32.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real looping normalisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished! The normalisation took 0:00:05.756819 seconds!\n"
     ]
    }
   ],
   "source": [
    "starttime = datetime.datetime.now()\n",
    "\n",
    "# ---------------------------------------------------------------------------------\n",
    "# File to log images that fail normalization\n",
    "normalisation_fails_file = f\"{output_folder_stainnet}/0_failed_to_normalise.txt\" # 0 just for having the file listed as first\n",
    "\n",
    "with open(normalisation_fails_file, \"w\") as file:\n",
    "    file.write(\"The following are the tiles not normalised:\\n\")\n",
    "    \n",
    "    # Process each image in the input folder\n",
    "    for filename in os.listdir(INPUT_FOLDER):\n",
    "        image_path = os.path.join(INPUT_FOLDER, filename)\n",
    "\n",
    "        # Load and preprocess the image\n",
    "        img = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        try:\n",
    "            # Perform normalization\n",
    "            model_Net.eval()\n",
    "            with torch.no_grad():\n",
    "                img_net=model_Net(norm(img).cuda())\n",
    "                img_normed_array=un_norm(img_net)\n",
    "\n",
    "            # Convert the normalized image back to PIL format\n",
    "            img_normed_pil = Image.fromarray(img_normed_array)\n",
    "\n",
    "            # Save the normalized image\n",
    "            output_path = os.path.join(output_folder_stainnet, f\"{os.path.splitext(filename)[0]}_{normalisation_method}.jpg\") # or .png (but it's way bigger)\n",
    "            img_normed_pil.save(output_path)\n",
    "\n",
    "            #print(f\"Normalized image saved to: {output_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            file.write(f\"{filename}\\n\")\n",
    "            #print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "\n",
    "difference =  datetime.datetime.now() - starttime\n",
    "\n",
    "# eventually deleting the previous time log file\n",
    "for filename in os.listdir(output_folder_stainnet):\n",
    "    if filename.startswith(\"0_started_\"):\n",
    "        file_path = os.path.join(output_folder_stainnet, filename)\n",
    "        if os.path.isfile(file_path):  # Check if it is a file\n",
    "            os.remove(file_path)      # Delete the file\n",
    "            print(f\"Deleted: {file_path}\")\n",
    "\n",
    "# saving the start and finish time in the file's name for simplicity in the reading.\n",
    "with open(f\"{output_folder_stainnet}/0_started_at_{starttime}_finished_at_{datetime.datetime.now()}.txt\", \"w\") as file:\n",
    "    file.write(f\"The run started at {starttime} and finished at {datetime.datetime.now()}.\")\n",
    "\n",
    "print(f\"Finished! The normalisation took {difference} seconds!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Final - Saving the environment requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save package versions to a .txt file\n",
    "with open(\"requirements_for_stainnet_env.txt\", \"w\") as f:\n",
    "    subprocess.run([\"pip\", \"freeze\"], stdout=f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "he_stainnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
