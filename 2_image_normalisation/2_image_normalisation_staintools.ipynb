{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the package StainTools:\n",
    "- GitHub: https://github.com/Peter554/StainTools/tree/master\n",
    "  ```bash\n",
    "  pip install staintools\n",
    "  ```\n",
    "\n",
    "- The author suggests to use the conda through this [link](https://anaconda.org/conda-forge/python-spams) and the related code for installing the SPAMS dependency:\n",
    "  ```bash\n",
    "  conda install conda-forge::python-spams\n",
    "  conda install conda-forge/label/broken::python-spams\n",
    "  conda install conda-forge/label/cf201901::python-spams\n",
    "  conda install conda-forge/label/cf202003::python-spams\n",
    "  conda install conda-forge/label/gcc7::python-spams\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import staintools\n",
    "# import stain_utils as utils\n",
    "# import stainNorm_Reinhard\n",
    "# import stainNorm_Macenko\n",
    "# import stainNorm_Vahadane\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from multiprocessing import Pool, Lock\n",
    "import os\n",
    "import datetime\n",
    "import subprocess\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/disk2/work/gabgam/gigi_env/the_project/2_image_normalisation\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/disk2/user/gabgam/work/gigi_env/the_project/2_image_normalisation/\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "INPUT_FOLDER = \"../1_tiling/outputs/satac_C1/tiling_output/v3_allspots/tiles_100/\"  # Replace with the path to your folder containing images\n",
    "tiles_info = INPUT_FOLDER.split('/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. - Normalisation methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 - Macenko's method\n",
    "\n",
    "The normalisation is sequentially, but maybe in the future I'll integrate with a parallel one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/disk2/work/gabgam/gigi_env/the_project/2_image_normalisation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk2/user/gabgam/.local/lib/python3.8/site-packages/staintools/stain_normalizer.py:41: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  source_concentrations *= (self.maxC_target / maxC_source)\n",
      "/disk2/user/gabgam/.local/lib/python3.8/site-packages/staintools/stain_normalizer.py:41: RuntimeWarning: invalid value encountered in multiply\n",
      "  source_concentrations *= (self.maxC_target / maxC_source)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 73\u001b[0m\n\u001b[1;32m     70\u001b[0m         process_image(image_path, output_path)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 73\u001b[0m     \u001b[43mnormalize_images_sequentially\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINPUT_FOLDER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;66;03m# eventually deleting the previous time log file\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(output_folder):\n",
      "Cell \u001b[0;32mIn[2], line 70\u001b[0m, in \u001b[0;36mnormalize_images_sequentially\u001b[0;34m(input_folder, output_path)\u001b[0m\n\u001b[1;32m     67\u001b[0m image_paths \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(input_folder, image) \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(input_folder) \u001b[38;5;28;01mif\u001b[39;00m image\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpeg\u001b[39m\u001b[38;5;124m'\u001b[39m))]\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_path \u001b[38;5;129;01min\u001b[39;00m image_paths:\n\u001b[0;32m---> 70\u001b[0m     \u001b[43mprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 50\u001b[0m, in \u001b[0;36mprocess_image\u001b[0;34m(image_path, output_path)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# Read and normalize the image\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     to_transform \u001b[38;5;241m=\u001b[39m staintools\u001b[38;5;241m.\u001b[39mread_image(image_path)\n\u001b[0;32m---> 50\u001b[0m     transformed \u001b[38;5;241m=\u001b[39m \u001b[43mnormalizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_transform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# Convert the transformed array back to a PIL image\u001b[39;00m\n\u001b[1;32m     53\u001b[0m     img_normed_pil \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(np\u001b[38;5;241m.\u001b[39muint8(transformed))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/staintools/stain_normalizer.py:39\u001b[0m, in \u001b[0;36mStainNormalizer.transform\u001b[0;34m(self, I)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03mTransform an image.\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m:param I: Image RGB uint8.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03m:return:\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     38\u001b[0m stain_matrix_source \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextractor\u001b[38;5;241m.\u001b[39mget_stain_matrix(I)\n\u001b[0;32m---> 39\u001b[0m source_concentrations \u001b[38;5;241m=\u001b[39m \u001b[43mget_concentrations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mI\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstain_matrix_source\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m maxC_source \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpercentile(source_concentrations, \u001b[38;5;241m99\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m     41\u001b[0m source_concentrations \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxC_target \u001b[38;5;241m/\u001b[39m maxC_source)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/staintools/miscellaneous/get_concentrations.py:16\u001b[0m, in \u001b[0;36mget_concentrations\u001b[0;34m(I, stain_matrix, regularizer)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03mEstimate concentration matrix given an image and stain matrix.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m:return:\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     15\u001b[0m OD \u001b[38;5;241m=\u001b[39m convert_RGB_to_OD(I)\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mspams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlasso\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mOD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstain_matrix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregularizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtoarray()\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[0;32m~/miniconda3/envs/he_staintools/lib/python3.8/site-packages/spams.py:442\u001b[0m, in \u001b[0;36mlasso\u001b[0;34m(X, D, Q, q, return_reg_path, L, lambda1, lambda2, mode, pos, ols, numThreads, max_length_path, verbose, cholesky)\u001b[0m\n\u001b[1;32m    440\u001b[0m         ((indptr,indices,data,shape),path) \u001b[38;5;241m=\u001b[39m spams_wrap\u001b[38;5;241m.\u001b[39mlassoD(X,D,return_reg_path,L,lambda1,lambda2,mode,pos,ols,numThreads,max_length_path,verbose,cholesky)\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 442\u001b[0m         (indptr,indices,data,shape) \u001b[38;5;241m=\u001b[39m \u001b[43mspams_wrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlassoD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\u001b[43mreturn_reg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlambda1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlambda2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43mols\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnumThreads\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmax_length_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcholesky\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m alpha \u001b[38;5;241m=\u001b[39m ssp\u001b[38;5;241m.\u001b[39mcsc_matrix((data,indices,indptr),shape)\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_reg_path:\n",
      "File \u001b[0;32m~/miniconda3/envs/he_staintools/lib/python3.8/site-packages/spams_wrap.py:197\u001b[0m, in \u001b[0;36mlassoD\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlassoD\u001b[39m(\u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m    193\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03m    lassoD(Matrix< double > * X, Matrix< double > * D, bool return_reg_path, int L, double const constraint, double const lambda2, constraint_type mode, bool const pos, bool const ols, int const numThreads, int max_length_path, bool const verbose, bool cholevsky) -> SpMatrix< double >\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m    lassoD(Matrix< float > * X, Matrix< float > * D, bool return_reg_path, int L, float const constraint, float const lambda2, constraint_type mode, bool const pos, bool const ols, int const numThreads, int max_length_path, bool const verbose, bool cholevsky) -> SpMatrix< float > *\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_spams_wrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlassoD\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import staintools\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from multiprocessing import Pool, Lock\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "#%matplotlib inline\n",
    "\n",
    "starttime = datetime.datetime.now()\n",
    "\n",
    "os.chdir(\"/disk2/user/gabgam/work/gigi_env/the_project/2_image_normalisation/\")\n",
    "print(os.getcwd())\n",
    "\n",
    "# SET PATHS, HERE IS THE MOST IMPORTANT STEP, BE CAREFUL WITH IT.\n",
    "INPUT_FOLDER = \"../1_tiling/outputs/satac_C1/tiling_output/v3_allspots/tiles_100/\"  # Replace with the path to your folder containing images\n",
    "tiles_info = INPUT_FOLDER.split('/')\n",
    "\n",
    "\n",
    "\n",
    "# Define the paths\n",
    "TARGET_IMAGE_PATH = \"reference_images/reference_full.jpeg\"\n",
    "target_temp_path = \"target_is_\" + TARGET_IMAGE_PATH.split(\"/\")[1].split(\".\")[0]\n",
    "normalisation_method = 'staintools_macenko'\n",
    "output_folder = f\"./output/{tiles_info[3]}/{tiles_info[5]}/{tiles_info[6]}/{normalisation_method}/{target_temp_path}\"\n",
    "\n",
    "# Ensure the output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# File to log normalization failures\n",
    "normalisation_fails_file = f\"{output_folder}/0_failed_to_normalise.txt\"\n",
    "with open(normalisation_fails_file, \"w\") as file:\n",
    "    file.write(\"The following tiles have failed normalization:\\n\")\n",
    "\n",
    "# Compute target statistics from target image\n",
    "target = staintools.read_image(TARGET_IMAGE_PATH)\n",
    "normalizer = staintools.StainNormalizer(method='macenko')\n",
    "normalizer.fit(target)\n",
    "\n",
    "def process_image(image_path, output_path):\n",
    "    try:\n",
    "        # Read and normalize the image\n",
    "        to_transform = staintools.read_image(image_path)\n",
    "        transformed = normalizer.transform(to_transform)\n",
    "\n",
    "        # Convert the transformed array back to a PIL image\n",
    "        img_normed_pil = Image.fromarray(np.uint8(transformed))\n",
    "\n",
    "        # Define the output file path\n",
    "        output_image_path = os.path.join(output_path, f\"{os.path.splitext(os.path.basename(image_path))[0]}_st_macenko_normalized.jpg\")\n",
    "\n",
    "        # Save the normalized image\n",
    "        img_normed_pil.save(output_image_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Log failures\n",
    "        with open(normalisation_fails_file, \"a\") as file:\n",
    "            file.write(f\"{image_path}: {str(e)}\\n\")\n",
    "\n",
    "def normalize_images_sequentially(input_folder, output_path):\n",
    "    image_paths = [os.path.join(input_folder, image) for image in os.listdir(input_folder) if image.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "    \n",
    "    for image_path in image_paths:\n",
    "        process_image(image_path, output_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    normalize_images_sequentially(INPUT_FOLDER, output_folder)\n",
    "\n",
    "    # eventually deleting the previous time log file\n",
    "    for filename in os.listdir(output_folder):\n",
    "        if filename.startswith(\"0_started_\"):\n",
    "            file_path = os.path.join(output_folder, filename)\n",
    "            if os.path.isfile(file_path):  # Check if it is a file\n",
    "                os.remove(file_path)      # Delete the file\n",
    "                print(f\"Deleted: {file_path}\")\n",
    "\n",
    "    # saving the start and finish time in the file's name for simplicity in the reading.\n",
    "    with open(f\"{output_folder}/0_started_at_{starttime}_finished_at_{datetime.datetime.now()}.txt\", \"w\") as file:\n",
    "        file.write(f\"The run started at {starttime} and finished at {datetime.datetime.now()}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 - Reinhard's method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = datetime.datetime.now()\n",
    "\n",
    "# Define the paths\n",
    "TARGET_IMAGE_PATH = \"reference_images/reference_full.jpeg\"\n",
    "target_temp_path = \"target_is_\" + TARGET_IMAGE_PATH.split(\"/\")[1].split(\".\")[0]\n",
    "normalisation_method = 'staintools_reinhard'\n",
    "output_folder = f\"./output/{tiles_info[3]}/{tiles_info[5]}/{tiles_info[6]}/{normalisation_method}/{target_temp_path}\"\n",
    "\n",
    "# Ensure the output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# File to log normalization failures\n",
    "normalisation_fails_file = f\"{output_folder}/0_failed_to_normalise.txt\"\n",
    "with open(normalisation_fails_file, \"w\") as file:\n",
    "    file.write(\"The following tiles have failed normalization:\\n\")\n",
    "\n",
    "# Compute target statistics from target image\n",
    "target = staintools.read_image(TARGET_IMAGE_PATH)\n",
    "normalizer = staintools.ReinhardColorNormalizer()\n",
    "normalizer.fit(target)\n",
    "\n",
    "def process_image(image_path, output_path):\n",
    "    try:\n",
    "        # Read and normalize the image\n",
    "        to_transform = staintools.read_image(image_path)\n",
    "        transformed = normalizer.transform(to_transform)\n",
    "\n",
    "        # Convert the transformed array back to a PIL image\n",
    "        img_normed_pil = Image.fromarray(np.uint8(transformed))\n",
    "\n",
    "        # Define the output file path\n",
    "        output_image_path = os.path.join(output_path, f\"{os.path.splitext(os.path.basename(image_path))[0]}_st_reinhard_normalized.jpg\")\n",
    "\n",
    "        # Save the normalized image\n",
    "        img_normed_pil.save(output_image_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Log failures\n",
    "        with open(normalisation_fails_file, \"a\") as file:\n",
    "            file.write(f\"{image_path}: {str(e)}\\n\")\n",
    "\n",
    "def normalize_images_sequentially(input_folder, output_path):\n",
    "    image_paths = [os.path.join(input_folder, image) for image in os.listdir(input_folder) if image.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "    \n",
    "    for image_path in image_paths:\n",
    "        process_image(image_path, output_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    normalize_images_sequentially(INPUT_FOLDER, output_folder)\n",
    "\n",
    "    with open(f\"{output_folder}/0_started_at_{starttime}_finished_at_{datetime.datetime.now()}.txt\", \"w\") as file:\n",
    "        file.write(f\"The run started at {starttime} and finished at {datetime.datetime.now()}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 - Vahadane's method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = datetime.datetime.now()\n",
    "\n",
    "# Define the paths\n",
    "TARGET_IMAGE_PATH = \"reference_images/reference_full.jpeg\"\n",
    "target_temp_path = \"target_is_\" + TARGET_IMAGE_PATH.split(\"/\")[1].split(\".\")[0]\n",
    "normalisation_method = 'staintools_vahadane'\n",
    "output_folder = f\"./output/{tiles_info[3]}/{tiles_info[5]}/{tiles_info[6]}/{normalisation_method}/{target_temp_path}\"\n",
    "\n",
    "# Ensure the output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# File to log normalization failures\n",
    "normalisation_fails_file = f\"{output_folder}/0_failed_to_normalise.txt\"\n",
    "with open(normalisation_fails_file, \"w\") as file:\n",
    "    file.write(\"The following tiles have failed normalization:\\n\")\n",
    "\n",
    "# Compute target statistics from target image\n",
    "target = staintools.read_image(TARGET_IMAGE_PATH)\n",
    "normalizer = staintools.StainNormalizer(method='vahadane')\n",
    "normalizer.fit(target)\n",
    "\n",
    "def process_image(image_path, output_path):\n",
    "    try:\n",
    "        # Read and normalize the image\n",
    "        to_transform = staintools.read_image(image_path)\n",
    "        transformed = normalizer.transform(to_transform)\n",
    "\n",
    "        # Convert the transformed array back to a PIL image\n",
    "        img_normed_pil = Image.fromarray(np.uint8(transformed))\n",
    "\n",
    "        # Define the output file path\n",
    "        output_image_path = os.path.join(output_path, f\"{os.path.splitext(os.path.basename(image_path))[0]}_st_vahadane_normalized.jpg\")\n",
    "\n",
    "        # Save the normalized image\n",
    "        img_normed_pil.save(output_image_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Log failures\n",
    "        with open(normalisation_fails_file, \"a\") as file:\n",
    "            file.write(f\"{image_path}: {str(e)}\\n\")\n",
    "\n",
    "def normalize_images_sequentially(input_folder, output_path):\n",
    "    image_paths = [os.path.join(input_folder, image) for image in os.listdir(input_folder) if image.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "    \n",
    "    for image_path in image_paths:\n",
    "        process_image(image_path, output_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    normalize_images_sequentially(INPUT_FOLDER, output_folder)\n",
    "\n",
    "    with open(f\"{output_folder}/0_started_at_{starttime}_finished_at_{datetime.datetime.now()}.txt\", \"w\") as file:\n",
    "        file.write(f\"The run started at {starttime} and finished at {datetime.datetime.now()}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Final - Saving the environment requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save package versions to a .txt file\n",
    "with open(\"requirements_for_staintools_env.txt\", \"w\") as f:\n",
    "    subprocess.run([\"pip\", \"freeze\"], stdout=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**CODES FOR PARALLEL COMPUTING (to be done)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(args):\n",
    "    '''\n",
    "    This function normalise the image given as input with the relative method and correclty saves in the specified folder.\n",
    "    '''\n",
    "    image_path, method, saving_folder = args\n",
    "\n",
    "    # Read the image and standardize brigthness\n",
    "    to_transform = staintools.read_image(image_path)\n",
    "    to_transform = staintools.LuminosityStandardizer.standardize(to_transform)\n",
    "\n",
    "    # Stain normalize\n",
    "    normalizer = staintools.StainNormalizer(method=method)\n",
    "    normalizer.fit(target)\n",
    "    transformed = normalizer.transform(to_transform)\n",
    "\n",
    "    # Save normalized image\n",
    "    transformed_pil = Image.fromarray(transformed)\n",
    "    image_name = os.path.basename(image_path).split(\".\")[0] + f\"_{method}.jpeg\"\n",
    "    save_path = os.path.join(saving_folder, image_name)\n",
    "    transformed_pil.save(save_path)\n",
    "\n",
    "\n",
    "def normalize_image(image_path, target, method, output_dir):\n",
    "    '''\n",
    "    This function normalise the image given as input with the relative method and correclty saves in the specified folder.\n",
    "    '''\n",
    "    try:\n",
    "        # Read and standardize the image\n",
    "        to_transform = staintools.read_image(image_path)\n",
    "        to_transform = staintools.LuminosityStandardizer.standardize(to_transform)\n",
    "\n",
    "        # Stain normalization\n",
    "        normalizer = staintools.StainNormalizer(method=method)\n",
    "        normalizer.fit(target)\n",
    "        transformed = normalizer.transform(to_transform)\n",
    "\n",
    "        # Save the transformed image\n",
    "        image_name = os.path.basename(image_path)\n",
    "        output_path = os.path.join(output_dir, f\"{os.path.splitext(image_name)[0]}_{method}.jpeg\")\n",
    "        cv2.imwrite(output_path, cv2.cvtColor(transformed, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    # Skipping when image is almost or completely empty\n",
    "    except TissueMaskException:\n",
    "        print(f\"Skipping {image_path}: Empty tissue mask computed.\")\n",
    "        return None\n",
    "\n",
    "    return output_path\n",
    "\n",
    "\n",
    "\n",
    "def process_images_for_method(method):\n",
    "    '''\n",
    "    This function implement parallel normalisation processing of the image for the specified method.\n",
    "    '''\n",
    "\n",
    "    # Create output folder for the method\n",
    "    saving_folder_per_method = os.path.join(output_dir, f\"{method}_staintools/\")\n",
    "    os.makedirs(saving_folder_per_method, exist_ok=True)\n",
    "\n",
    "    # Collect all image paths in the input directory\n",
    "    image_paths = [\n",
    "        os.path.join(input_dir, image)\n",
    "        for image in os.listdir(input_dir)\n",
    "        if image.startswith((\"tissue\")) # and image.endswith((\".jpg\")) \n",
    "    ]\n",
    "\n",
    "    # argument tuples for multiprocessing\n",
    "    args = [(image_path, method, saving_folder_per_method) for image_path in image_paths]\n",
    "\n",
    "    # parallel processing of the images\n",
    "    with Pool() as pool:\n",
    "        pool.map(normalize_image, args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input and output directories\n",
    "input_dir = f\"../1_tiling/outputs/{SAMPLE_NAME}/tiling_output/\"\n",
    "output_dir = f\"./output/{SAMPLE_NAME}/normalised_he/\"\n",
    "\n",
    "# preprocess the reference target image\n",
    "target = staintools.read_image(\"./reference_images/reference_sparser.jpeg\") # check for the other images, results may change\n",
    "target = staintools.LuminosityStandardizer.standardize(target)\n",
    "\n",
    "# normalization methods\n",
    "methods = [\"macenko\", \"vahadane\"]\n",
    "if __name__ == \"__main__\":\n",
    "    for method in methods:\n",
    "        process_images_for_method(method)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "he_staintools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
